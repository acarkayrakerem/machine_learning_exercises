{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+68fso5Mpkvb+eN+ps+Dr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "Q6CXHRf9z3OY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kIEPVsc0ykUV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import gradio as gr\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLAMA = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "JjZtdccZDUgg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prices(ticker, market_type, volatility, n_samples, base_price=None):\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "You are a financial data simulator.\n",
        "Generate a synthetic OHLCV time series dataset.\n",
        "\"\"\"\n",
        "    user_message= f\"\"\"\n",
        "Conditions:\n",
        "- Ticker: {ticker}\n",
        "- Market type: {market_type}\n",
        "- Volatility regime: {volatility}\n",
        "- Number of rows: {n_samples}\n",
        "- Base Price: {base_price}\n",
        "\n",
        "Output format:\n",
        "- Output ONLY CSV.\n",
        "- Include a header row.\n",
        "- Columns (in this exact order): timestamp, high, low.\n",
        "- Use 1-day intervals starting from Day 1 (e.g. \"Day 1\", \"Day 2\", ...).\n",
        "- Ensure: high >= low, low <= high.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "     ]\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n",
        "    outputs = model.generate(inputs, max_new_tokens=2000)\n",
        "    generated_text = tokenizer.decode(outputs[0],skip_special_tokens=True).strip()\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "aiF0ImAX9Ky1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Synthetic Price Reaction Generator\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            ticker = gr.Textbox(label=\"Ticker\", value=\"AAPL\")\n",
        "            n_samples = gr.Slider(\n",
        "                label=\"Number of samples\",\n",
        "                minimum=7, maximum=30, value=7, step=1\n",
        "            )\n",
        "            market_type = gr.Dropdown(\n",
        "                label=\"Market\",\n",
        "                choices=[\"Bullish\", \"Bearish\", \"Neutral\"],\n",
        "                value=\"Neutral\"\n",
        "            )\n",
        "            volatility = gr.Dropdown(\n",
        "                label=\"Volatility Regime\",\n",
        "                choices=[\"Low\", \"Medium\", \"High\"],\n",
        "                value=\"Medium\"\n",
        "            )\n",
        "            base_price = gr.Number(label=\"Base price (optional)\", value=100)\n",
        "\n",
        "            run_btn = gr.Button(\"Generate\")\n",
        "\n",
        "        with gr.Column():\n",
        "            generated_box = gr.Textbox(\n",
        "                label=\"Output\",\n",
        "                lines=15\n",
        "            )\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=generate_prices,\n",
        "        inputs=[ticker, market_type, volatility, n_samples, base_price],\n",
        "        outputs=[generated_box],\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "5jcfsMgezrs6",
        "outputId": "6210f212-9f9d-4dd4-8f03-85f2121761aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8a32d9dae92dfb7323.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8a32d9dae92dfb7323.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}